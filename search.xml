<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[聊聊HTTP1.x和HTTP2.0]]></title>
    <url>%2Farticles%2F%E8%81%8A%E8%81%8AHTTP1-x%E5%92%8CHTTP2-0%2F</url>
    <content type="text"><![CDATA[一、HTTP 1.xHTTP协议（HyperTextTransferProtocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传输协议。 1. HTTP发展史： 2. HTTP的基本优化影响一个 HTTP 网络请求的因素主要有两个：带宽和延迟。 带宽：如果说我们还停留在拨号上网的阶段，带宽可能会成为一个比较严重影响请求的问题，但是现在网络基础建设已经使得带宽得到极大的提升，我们不再会担心由带宽而影响网速，那么就只剩下延迟了。 延迟： 浏览器阻塞（HOL blocking）：浏览器会因为一些原因阻塞请求。浏览器对于同一个域名，同时只能有 4 个连接（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。 DNS 查询（DNS Lookup）：浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。** 建立连接（Initial connection）：HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。 HTTP 性能优化的关键并不在于高带宽，而是低延迟 3. HTTP1.0和HTTP1.1的一些区别HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在： 缓存处理 在HTTP1.0中主要使用header里的If-Modified-Since，Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since， If-Match， If-None-Match等更多可供选择的缓存头来控制缓存策略。 提供了更多可供选择的缓存头来控制缓存策略 带宽优化及网络连接的使用 HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 支持断点续传 错误通知的管理 在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 提供了更多的错误状态响应码 Host头处理 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 host域 长连接 HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。 支持长连接和pipelining 4. HTTPS与HTTP的一些区别 HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。 HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。 HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。 二、SPDY：Google提出的HTTP1.x优化方案2012年google如一声惊雷提出了SPDY的方案，优化了HTTP1.X的请求延迟，解决了HTTP1.X的安全性，具体如下： 降低延迟 针对HTTP高延迟的问题，SPDY优雅的采取了多路复用（multiplexing）。多路复用通过多个请求stream共享一个tcp连接的方式，解决了HOL blocking的问题，降低了延迟同时提高了带宽的利用率。 请求优先级（request prioritization） 多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY允许给每个request设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的html内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。 header压缩。 前面提到HTTP1.x的header很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。 基于HTTPS的加密协议传输 大大提高了传输数据的可靠性。 服务端推送（server push） 采用了SPDY的网页，例如我的网页有一个sytle.css的请求，在客户端收到sytle.css数据的同时，服务端会将sytle.js的文件推送给客户端，当客户端再次尝试获取sytle.js时就可以直接从缓存中获取到，不用再发请求了。SPDY构成图： SPDY位于HTTP之下，TCP和SSL之上，这样可以轻松兼容老版本的HTTP协议(将HTTP1.x的内容封装成一种新的frame格式)，同时可以使用已有的SSL功能。 三、HTTP 2.0横空出世1. 性能惊人HTTP 2.0 的出现，相比于 HTTP 1.x ，大幅度的提升了 web 性能。 这是 Akamai 公司建立的一个官方的演示，用以说明 HTTP/2 相比于之前的 HTTP/1.1 在性能上的大幅度提升。 同时请求 379 张图片，从Load time 的对比可以看出 HTTP/2 在速度上的优势。 2. HTTP2.0：SPDY的升级版HTTP2.0可以说是SPDY的升级版（其实原本也是基于SPDY设计的），但是，HTTP2.0 跟 SPDY 仍有不同的地方，如下： HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS。 HTTP2.0 消息头的压缩算法采用 HPACK，而非 SPDY 采用的 DEFLATE。 四、HTTP 2.0 和 HTTP1.1 区别后面我们将通过几个方面来说说HTTP 2.0 和 HTTP1.1 区别，并且和你解释下其中的原理。 区别一：多路复用 TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。 HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。 多路复用允许单一的 HTTP/2 连接同时发起多重的请求-响应消息。看个例子： 整个访问流程第一次请求index.html页面，之后浏览器会去请求style.css和scripts.js的文件。左边的图是顺序加载两个个文件的，右边则是并行加载两个文件。 通过下面两张图，我们可以更加深入的认识多路复用： HTTP 1.x： HTTP 2： 总结下： 多路复用技术：单连接多资源的方式，减少服务端的链接压力，内存占用更少，连接吞吐量更大；由于减少TCP 慢启动时间，提高传输的速度。 区别二：二进制分帧 TCP连接相当于两根管道（一个用于服务器到客户端，一个用于客户端到服务器），管道里面数据传输是通过字节码传输，传输是有序的，每个字节都是一个一个来传输。 我们知道HTTP底层其实依赖的是TCP协议，那问题是在同一个连接里面同时发生两个请求响应着是怎么做到的？ 首先你要知道，TCP连接相当于两根管道（一个用于服务器到客户端，一个用于客户端到服务器），管道里面数据传输是通过字节码传输，传输是有序的，每个字节都是一个一个来传输。 例如客户端要向服务器发送Hello、World两个单词，只能是先发送Hello再发送World，没办法同时发送这两个单词。不然服务器收到的可能就是HWeolrllod（注意是穿插着发过去了，但是顺序还是不会乱）。这样服务器就懵b了。 接上面的问题，能否同时发送Hello和World两个单词能，当然也是可以的，可以将数据拆成包，给每个包打上标签。发的时候是这样的①H ②W ①e ②o ①l ②r ①l ②l ①o ②d。这样到了服务器，服务器根据标签把两个单词区分开来。实际的发送效果如下图： 要实现上面的效果我们引入一个新的概念就是：二进制分帧。 二进制分帧层 在 应用层(HTTP/2)和传输层(TCP or UDP)之间。HTTP/2并没有去修改TCP协议而是尽可能的利用TCP的特性。 在二进制分帧层中， HTTP/2 会将所有传输的信息分割为帧（frame），并对它们采用二进制格式的编码 ，其中 首部信息会被封装到 HEADER frame，而相应的 Request Body 则封装到 DATA frame 里面。 区别三：首部压缩为什么要压缩？在 HTTP/1 中，HTTP 请求和响应都是由「状态行、请求 / 响应头部、消息主体」三部分组成。一般而言，消息主体都会经过 gzip 压缩，或者本身传输的就是压缩过后的二进制文件（例如图片、音频），但状态行和头部却没有经过任何压缩，直接以纯文本传输。 随着 Web 功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输 UserAgent、Cookie 这类不会频繁变动的内容，完全是一种浪费。 我们再用通俗的语言解释下，压缩的原理。头部压缩需要在支持 HTTP/2 的浏览器和服务端之间: 维护一份相同的静态字典（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合； 维护一份相同的动态字典（Dynamic Table），可以动态的添加内容； 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）； 静态字典的作用有两个： 对于完全匹配的头部键值对，例如 “:method :GET”，可以直接使用一个字符表示； 对于头部名称可以匹配的键值对，例如 “cookie :xxxxxxx”，可以将名称使用一个字符表示。 HTTP/2 中的静态字典如下（以下只截取了部分，完整表格在这里）： 同时，浏览器和服务端都可以向动态字典中添加键值对，之后这个键值对就可以使用一个字符表示了。需要注意的是，动态字典上下文有关，需要为每个 HTTP/2 连接维护不同的字典。在传输过程中使用，使用字符代替键值对大大减少传输的数据量。 区别四：HTTP2支持服务器推送 意思是说，当我们对支持HTTP2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。 服务器端推送的这些资源其实存在客户端的某处地方，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。 服务端推送是一种在客户端请求之前发送数据的机制。当代网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP/1.x中这些资源每一个都必须明确地请求。这可能是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。 为了改善延迟，HTTP/2引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前。一个服务器经常知道一个页面需要很多附加资源，在它响应浏览器第一个请求的时候，可以开始推送这些资源。这允许服务端去完全充分地利用一个可能空闲的网络，改善页面加载时间。 五、HTTP2.0特性解析1. HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？ HTTP/1.x：一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接； HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞； HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；具体如图： 2. 服务端推送(server push)到底是什么？服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。具体如下： 普通的客户端请求过程： 服务端推送的过程： 但是，现阶段用 server push 推送静态资源并不是一件有意义的事情，原因在于： HTML 文件通常不大，而且样式表一般很靠前，浏览器发现这类静态资源的时间几乎可以忽略不计 HTTP/2 已经能够复用 TCP 连接了，请求不再像以前那样昂贵，请求的实际数据很小，发送请求的时间也几乎可以忽略不计 国内的 CDN 普遍不支持 server push，这意味着，如果要推送静态资源，就必须耗费自己服务器的带宽，同时也享受不到 CDN 的各种好处了 静态资源通常会被缓存很长时间，提前推送的话，在大多数情况下反而会浪费流量 因此，Server push推送的资源并不是静态资源，而应该是 API。当然，Server push对要推送的资源是有限制的：其请求必须是可缓存的、安全的，而且不能带有请求体。换句话说，Server push可以推 GET 和 HEAD 请求的响应。 3. 为什么需要头部压缩？假定一个页面有100个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1kb的消息头（这同样也并不少见，因为Cookie和引用等东西的存在）, 则至少需要多消耗100kb来获取这些消息头。HTTP2.0可以维护一个字典，差量更新HTTP头部，大大降低因头部传输产生的流量。具体参考：HTTP/2 头部压缩技术介绍 4. HTTP2.0多路复用有多好？HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。 六、参考HTTP1.0和HTTP2.0的区别]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[宏观视角看Golang中Map的内部实现]]></title>
    <url>%2Farticles%2F%E5%AE%8F%E8%A7%82%E8%A7%86%E8%A7%92%E7%9C%8BGolang%E4%B8%AD%E7%9A%84Map%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[介绍网上已经有很多关于slices内部实现的文章。但是每次一说到map，我们好像就一脸懵哔了。我想知道为什么，然后我就去翻看了map的源码，最终一切都真相大白了。orz…. 至少对我来说，这些源码是有点复杂的。话虽如此，我认为我们还是可以从一个宏观的视角来看看map到底是如何构建和扩容的。并且这至少要能够解释map为什么是无序的、高效的、快速的。 创建和使用map首先让我们来看看，如何创建一个map并在其中存储一些值： 1234567// Create an empty map with a key and value of type stringcolors := map[string]string&#123;&#125;// Add a few keys/value pairs to the mapcolors["AliceBlue"] = "#F0F8FF"colors["Coral"] = "#FF7F50"colors["DarkGray"] = "#A9A9A9" 当我们想向map添加一些值时，我们总是会给每个值指定一个key。每个key是为了让我们后续可以在不遍历整个集合的前提下快速的查到对应的值。 1fmt.Printf("Value: %s", colors["Coral"]) 如果我们遍历整个map，我们取到的值的顺序不一定会和我们当初存进去的顺序一致。事实上，每次执行以下代码，所得到的顺序都会不一样： 12345678910111213141516171819colors := map[string]string&#123;&#125;colors["AliceBlue"] = "#F0F8FF"colors["Coral"] = "#FF7F50"colors["DarkGray"] = "#A9A9A9"colors["ForestGreen"] = "#228B22"colors["Indigo"] = "#4B0082"colors["Lime"] = "#00FF00"colors["Navy"] = "#000080"colors["Orchid"] = "#DA70D6"colors["Salmon"] = "#FA8072"for key, value := range colors &#123; fmt.Printf("%s:%s, ", key, value)&#125;//Output://AliceBlue:#F0F8FF, DarkGray:#A9A9A9, Indigo:#4B0082, Coral:#FF7F50,//ForestGreen:#228B22, Lime:#00FF00, Navy:#000080, Orchid:#DA70D6,//Salmon:#FA8072 现在，我们已经学会如何创建一个map，并对其进行设置和遍历了。接下来，让我们揭开这一切的面纱。：） map的内部结构Go中的map是通过hash table实现的。如果你还不知道hash table是什么，网上已经有很多相关的文章了。或许你可以从Wiki开始。 Go map的hash table是一个桶数组。桶的数量总是设置成2的乘方。当你执行一个map操作的时候，比如（colors[“Black”] = “#000000”）,一个指向相应值的hash key就会生成。在这个例子中，字符串”Black”就是用来生成hash key的。所生成的hash key的低位字节用来定位到哪一个桶。 桶定位好了之后，就可以存储、移除、查找键值对了。如果我们进一步看看桶的内部实现，就会发现它是由两部分组成的。其一，在这个hash key中有一个位数组，它的高八位用来定位到桶。这个数组保证了存储在各自桶中的键值对不会重复。其二，有一个字节数组，其中存储了所有的键值对。这个数组讲所有的键，所有的值分别打包存放在各自的桶中。 当我们遍历一个map的时候，迭代器依次访问所有的桶，然后按照它们在字节数组中的顺序依次返回键值对。这就是为什么map的输出是无序集合。hash keys决定了map的遍历顺序，因为它们决定了每个键值对最终会进入哪个桶。 内存和桶溢出键值对之所以要这样打包存放在一个字节数组中，有一个很重要的原因。那就是，假如所有的键、值都按照key/value/key/value的方式存储，在每个键值对之间就需要去额外填充适当的空间，才能够保持内存边界对齐。举个🌰，我们申明如下这样的一个map： 1map[int64]int8 这个map的每一个键值对中，一个字节大小的值都会导致7个字节的额外填充。而通过将键值对以key/key/value/value的方式存储，唯一可能需要额外填充的地方就是在字节数组的最后，而不是之间。消除这些不必要的填充字节，帮助桶和map省了很多的内存开销。想要学习更多边界对齐相关的知识，可以读读这篇文章。 每个桶配置成了只能存储8个键值对。如果有第九个键值对需要加入到这个已经满了的桶中时，一个新的桶就会被创建，并被各自的桶所引用。 map扩容当我们持续的对一个map添加/删除键值对时，map的性能会开始下降。决定了一个map何时触发扩容的负载阈值是由以下四个因子决定的： 1234overflow : Percentage of buckets which have an overflow bucketbytes/entry : Number of overhead bytes used per key/value pairhitprobe : Number of entries that need to be checked when looking up a keymissprobe : Number of entries that need to be checked when looking up an absent key 目前，源码中用的具体的负载阈值如下： LOAD %overflow bytes/entry hitprobe missprobe 6.50 20.90 10.79 4.25 6.50 发生扩容时，首先申请一个指针指向旧桶的地址。然后分配一个二倍于原来桶数量的桶数组。这会导致出现大量的内存分配，但是因为这些申请的内存并没有初始化，所以这些分配时很快的。 一旦新的桶数组的内存可用了，旧的桶数组中的所有键值对就可以搬到新的桶数组中去了。每次搬迁发生在map新增/移除键值对的时候。在旧桶数组中的同一个桶的键值对可能被搬运到新桶数组的不同的桶中去。搬运算法试图让键值对均匀的分布在新的桶数组中。 这是一个非常精巧的设计，因为迭代器仍然需要去遍历旧的桶，直到旧的桶全部搬运完毕。在迭代操作的过程中，键值对的返回方式也受到了这一设计的影响。采用了很多方案来确保在map扩容的过程中迭代器能正常工作。 总结正如开头所说的，这篇文章只是在一个宏观的视角下看map的内部结构和它是如何扩容的。源码是用c写的，使用了很多的内存和指针操作来保证效率和可靠。 当然了，现在的实现方式在未来的任何一个时间都可能会发生改变。但是这并不影响我们正确使用map的能力。这个视角让我们明白了，当我们提前知道会有多少key需要存储时，最好在初始化的时候就把相应大小的内存分配好。同时也解释了为什么map是一个无序的集合，和为什么在遍历map的时候，迭代器的行为看起来像是随机的。 此文为译文，原文地址。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>map</tag>
        <tag>internals</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中slice的使用技巧]]></title>
    <url>%2Farticles%2FGolang%E4%B8%ADslice%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[由于引入了内建的append方法，container/vector包的很多方法在Go 1中被移除了，因为我们认为可以通过使用append和copy来代替它们。 下面就是container/vector包中的方法，我们通过slice来模拟实现。 常规操作Append Vector1a = append(a, b...) Copy123456b = make([]T, len(a))copy(b, a)// orb = append([]T(nil), a...)// orb = append(a[:0:0], a...) // 查看 https://github.com/go101/go101/wiki Cut1a = append(a[:i], a[j:]...) Delete123a = append(a[:i], a[i+1:]...)// ora = a[:i+copy(a[i:], a[i+1:])] Delete without preserving order12a[i] = a[len(a)-1] a = a[:len(a)-1] 注意: 如果该元素类型是一个指针，或者是一个包含需要被回收的指针类型字段的struct，上面的cut、delete实现可能会有潜在的内存泄漏的问题。一些元素的值可能会被a一直引用而不被释放，下面的代码可以解决这个问题。 12345678910111213141516// Cutcopy(a[i:], a[j:])for k, n := len(a)-j+i, len(a); k &lt; n; k++ &#123; a[k] = nil // 或者类型T的对应零值&#125;a = a[:len(a)-j+i]// Deletecopy(a[i:], a[i+1:])a[len(a)-1] = nil // 或者类型T的对应零值a = a[:len(a)-1]// 不保证原来顺序的Deletea[i] = a[len(a)-1]a[len(a)-1] = nila = a[:len(a)-1] Expand1a = append(a[:i], append(make([]T, j), a[i:]...)...) Extend1a = append(a, make([]T, j)...) Insert1a = append(a[:i], append([]T&#123;x&#125;, a[i:]...)...) 注意: 第二个append（指的👆代码块的中append([]T{x}, a[i:]...)）会利用原来slice底层的数组创建一个新的slice，然后将a[i:]中的元素copy到这个新的slice，最后再把这个新的slice复制回原来的a。 新的slice的创建（随之带来了多余的内存回收压力）和copy可以使用下面的方式来避免： 1234// Inserts = append(s, 0)copy(s[i+1:], s[i:])s[i] = x InsertVector1a = append(a[:i], append(b, a[i:]...)...) Pop/Shift1x, a = a[0], a[1:] Pop Back1x, a = a[len(a)-1], a[:len(a)-1] Push1a = append(a, x) Push Front/Unshift1a = append([]T&#123;x&#125;, a...) 一些奇技淫巧（前方高能……orz）无额外对象分配的filter这个技巧利用了slice会共享它底层数据存储和容量的特性，通过重用底层存储来过滤slice。当然了，原slice的内容也会相应发生改变。 123456b := a[:0]for _, x := range a &#123; if f(x) &#123; b = append(b, x) &#125;&#125; 反转将slice中的元素反转。 1234for i := len(a)/2-1; i &gt;= 0; i-- &#123; opp := len(a)-1-i a[i], a[opp] = a[opp], a[i]&#125; 下面的代码类似，只不过使用了两个游标。 123for left, right := 0, len(a)-1; left &lt; right; left, right = left+1, right-1 &#123; a[left], a[right] = a[right], a[left]&#125; 洗牌Fisher–Yates算法。 从go1.10开始，已经在包math/rand.Shuffle中原生支持了。 1234for i := len(a) - 1; i &gt; 0; i-- &#123; j := rand.Intn(i + 1) a[i], a[j] = a[j], a[i]&#125; 最小化内存使用的批量处理方法如果你想分批处理一个很大的slice，这个技巧会很有用！ 1234567891011actions := []int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;batchSize := 3var batches [][]intfor batchSize &lt; len(actions) &#123; actions, batches = actions[batchSize:], append(batches, actions[0:batchSize:batchSize])&#125;batches = append(batches, actions)fmt.Println(result)// [[0 1 2] [3 4 5] [6 7 8] [9]] in-place 去重法123456789101112131415import "sort"in := []int&#123;3,2,1,4,3,2,1,4,1&#125; // 任何实现了sort接口的类型都可以sort.Ints(in)j := 0for i := 1; i &lt; len(in); i++ &#123; if in[j] == in[i] &#123; continue &#125; j++ in[i], in[j] = in[j], in[i]&#125;result := in[:j+1]fmt.Println(result) // [1 2 3 4] 注：本文源自Golang官方Wiki文章，且在不定期更新，本人也会持续跟进～]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>slice</tag>
        <tag>tricks</tag>
      </tags>
  </entry>
</search>
